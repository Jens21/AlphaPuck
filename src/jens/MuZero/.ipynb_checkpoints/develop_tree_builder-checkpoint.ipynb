{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a1ce76-4e2d-4705-8f13-e985eaa222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import laserhockey.hockey_env as h_env\n",
    "\n",
    "from network import Network\n",
    "from own_env import OwnEnv\n",
    "from action_selection import ActionSelection\n",
    "from utils import ACTIONS_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a70a001-af5b-4acd-9962-874b7eccd8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = OwnEnv()\n",
    "opponent = h_env.BasicOpponent(weak=True)\n",
    "action_selection = ActionSelection(0.975, 5)\n",
    "net = Network().eval()\n",
    "net.load_state_dict(th.load('checkpoints/agent_2500.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fbad84-38f3-4326-bff3-0adc574917d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_actions = len(ACTIONS_T)\n",
    "gamma = 0.975\n",
    "n_best=10\n",
    "n_times = 2\n",
    "\n",
    "def exploitation_v3(net, obs):\n",
    "        obs_in = th.from_numpy(obs)[None].float()\n",
    "        latent_states, state_values, policy_logits = net.initial_inference(obs_in)\n",
    "        search_depths = th.FloatTensor([0])\n",
    "        value_prefixes = th.FloatTensor([0])\n",
    "        action_indices = th.arange(n_actions)\n",
    "\n",
    "        for i in range(n_times):\n",
    "            indices = th.argsort(state_values, descending=True)\n",
    "            latent_states = latent_states[indices]  # [3, 64]\n",
    "            state_values = state_values[indices]  # [3]\n",
    "            search_depths = search_depths[indices]\n",
    "            value_prefixes = value_prefixes[indices]\n",
    "            if i != 0:\n",
    "                action_indices = action_indices[indices]\n",
    "\n",
    "            latent_best = latent_states[:n_best, None, None].tile(1, n_actions, n_actions,\n",
    "                                                                  1)  # [n_best, n_actions, n_actions, obs_dim]\n",
    "            actions1 = ACTIONS_T[None, :, None].tile(latent_best.shape[0], 1, n_actions,\n",
    "                                                     1)  # [n_best, n_actions, n_actions, act_dim]\n",
    "            actions2 = ACTIONS_T[None, None, :].tile(latent_best.shape[0], n_actions, 1,\n",
    "                                                     1)  # [n_best, n_actions, n_actions, act_dim]\n",
    "            search_depths_best = search_depths[:n_best, None, None].tile(1, n_actions,\n",
    "                                                                         n_actions)  # [n_best, n_actions, n_actions]\n",
    "            value_prefixes_best = value_prefixes[:n_best, None, None].tile(1, n_actions,\n",
    "                                                                           n_actions)  # [n_best, n_actions, n_actions]\n",
    "\n",
    "            latent_out, rewards, _, next_state_values, _ = net.recurrent_inference(latent_best.flatten(end_dim=2),\n",
    "                                                                                   actions1.flatten(end_dim=2),\n",
    "                                                                                   actions2.flatten(end_dim=2))\n",
    "\n",
    "            latent_out = latent_out.reshape(latent_best.shape)  # [n_best, n_actions, n_actions, obs_dim]\n",
    "            rewards = rewards.reshape(latent_best.shape[:3])  # [n_best, n_actions, n_actions]\n",
    "            next_state_values = next_state_values.reshape(latent_best.shape[:3])  # [n_best, n_actions, n_actions]\n",
    "            value_prefixes_best = value_prefixes_best + rewards * (\n",
    "                        gamma ** search_depths_best)  # [n_best, n_actions, n_actions]\n",
    "            state_values_best = value_prefixes_best + next_state_values * (\n",
    "                        gamma ** (search_depths_best + 1))  # [n_best, n_actions, n_actions]\n",
    "\n",
    "            n_mult = latent_out.shape[0] * latent_out.shape[1]\n",
    "            state_values_append, min_indices = state_values_best.min(dim=2)  # [3, 25]\n",
    "            latent_append = latent_out.flatten(end_dim=1)[th.arange(n_mult), min_indices.flatten()].reshape(\n",
    "                (latent_out.shape[0], latent_out.shape[1], -1))\n",
    "            value_prefixes_append = value_prefixes_best.flatten(end_dim=1)[\n",
    "                th.arange(n_mult), min_indices.flatten()].reshape((latent_out.shape[0], latent_out.shape[1]))\n",
    "            search_depths_append = search_depths[:n_best, None].tile(1, n_actions) + 1\n",
    "\n",
    "            state_values = th.concat([state_values[n_best:], state_values_append.flatten()])\n",
    "            value_prefixes = th.concat([value_prefixes[n_best:], value_prefixes_append.flatten()])\n",
    "            latent_states = th.concat([latent_states[n_best:], latent_append.flatten(end_dim=1)])\n",
    "            search_depths = th.concat([search_depths[n_best:], search_depths_append.flatten()])\n",
    "\n",
    "            if i != 0:\n",
    "                action_indices = th.concat(\n",
    "                    [action_indices[n_best:], action_indices[:n_best, None].tile(1, n_actions).flatten()])\n",
    "\n",
    "        idx = th.argmax(state_values)\n",
    "        max_action_idx = action_indices[idx].item()\n",
    "\n",
    "        policy_distr = state_values + 1.01\n",
    "        policy_distr /= policy_distr.sum()\n",
    "        policy_distr = policy_distr ** 4\n",
    "\n",
    "        return max_action_idx, policy_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4aeb1e8a-f3dd-4855-b734-8f5aa4638f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "from utils import ACTIONS_T\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, Q, latent_state):\n",
    "        self.N = th.zeros(len(ACTIONS_T), dtype=th.float)\n",
    "        self.Q = Q\n",
    "        self.R = th.zeros(len(ACTIONS_T), dtype=th.float)\n",
    "        self.S = [None] * len(ACTIONS_T)\n",
    "\n",
    "        self.latent_state = latent_state\n",
    "\n",
    "class TreeBuilder():\n",
    "\n",
    "    def __init__(self, gamma, n_simulations):\n",
    "        self.gamma = gamma\n",
    "        self.n_simulations = n_simulations\n",
    "        self.n_actions = len(ACTIONS_T)\n",
    "\n",
    "    def build_tree(self, obs, net, evaluation=True):\n",
    "        inp_obs = th.from_numpy(obs)[None].float()\n",
    "\n",
    "        latent_state, _, q_values = net.initial_inference(inp_obs)\n",
    "        root_node = Node(Q=q_values[0], latent_state=latent_state)\n",
    "\n",
    "        if not evaluation:\n",
    "            root_node.Q = root_node.Q + (th.rand(self.n_actions)*2-1)*0.1 # add random noise in [-0.25, 0.25]\n",
    "\n",
    "        for i in range(self.n_simulations):\n",
    "            l_nodes, l_action_indices = self.selection(root_node)\n",
    "            last_node, last_action_idx = l_nodes[-1], l_action_indices[-1]\n",
    "            value = self.expansion(net, last_node, last_action_idx)\n",
    "            self.backup(l_nodes, l_action_indices, value)\n",
    "            # print(root_node.Q)\n",
    "\n",
    "        return root_node\n",
    "\n",
    "    def selection(self, root_node):\n",
    "        l_nodes = [root_node]\n",
    "        l_action_indices = []\n",
    "\n",
    "        while True:\n",
    "            node = l_nodes[-1]\n",
    "\n",
    "            Q_ = (node.Q + 1)/2\n",
    "            n_sum = th.maximum(th.FloatTensor([1]), node.N.sum())\n",
    "            ucb = Q_ + n_sum**0.8 / (1 + node.N) * 0.15\n",
    "\n",
    "            action_idx = ucb.argmax()\n",
    "            l_action_indices.append(action_idx)\n",
    "\n",
    "            if node.S[action_idx] is None:\n",
    "                break\n",
    "            else:\n",
    "                l_nodes.append(node.S[action_idx])\n",
    "\n",
    "        return l_nodes, l_action_indices\n",
    "\n",
    "    def expansion(self, net, node, action_idx):\n",
    "        action_1 = ACTIONS_T[action_idx][None].tile(self.n_actions, 1) # [1, 4]\n",
    "        action_2 = ACTIONS_T                                        # [25, 4]\n",
    "        latent_inp = node.latent_state.tile(self.n_actions, 1)  # [1, 64]\n",
    "        next_latent_state, rewards, rewards_logits, next_state_values, q_values = net.recurrent_inference(latent_inp, action_1, action_2)\n",
    "\n",
    "        state_values = rewards + self.gamma * next_state_values\n",
    "        min_idx = state_values.argmin()\n",
    "        next_latent_state = next_latent_state[min_idx][None]\n",
    "        reward = rewards[min_idx]\n",
    "        value = next_state_values[min_idx]\n",
    "\n",
    "        child_node = Node(q_values[0], next_latent_state)\n",
    "        node.S[action_idx] = child_node\n",
    "        node.R[action_idx] = reward\n",
    "\n",
    "        return value\n",
    "\n",
    "    def backup(self, l_nodes, l_action_indices, value):\n",
    "        G = value\n",
    "        for node, action_idx in zip(reversed(l_nodes), reversed(l_action_indices)):\n",
    "            G = node.R[action_idx] + self.gamma * G\n",
    "\n",
    "            node.Q[action_idx] = (node.N[action_idx] * node.Q[action_idx] + G) / (node.N[action_idx] + 1)\n",
    "            node.Q[action_idx] = node.Q[action_idx].clip(-1, 1)\n",
    "            node.N[action_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17b463d-e6b0-4247-bf48-e66854036979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_builder = TreeBuilder(0.99, 15)\n",
    "def exploitation_tree(net, obs):\n",
    "    net.eval()\n",
    "\n",
    "    with th.no_grad():\n",
    "        root_node = tree_builder.build_tree(obs, net, evaluation=True)\n",
    "\n",
    "        action_idx_exploitation = root_node.Q.argmax()\n",
    "        policy_distr = root_node.Q\n",
    "        # print(root_node.Q, (root_node.N==15).any())\n",
    "        sample_distr = policy_distr**4\n",
    "\n",
    "        return action_idx_exploitation, policy_distr, sample_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e7da53-aee1-436f-a822-6f9c50ed5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1, _ = env.reset()\n",
    "obs2 = env.obs_agent_two()\n",
    "l_obs = [obs1]\n",
    "\n",
    "while True:\n",
    "    env.render()\n",
    "    max_action_idx, policy_distr,_ = exploitation_tree(net, obs1)\n",
    "    action1 = ACTIONS_T[max_action_idx]\n",
    "    action2 = opponent.act(obs2)\n",
    "\n",
    "    obs1, rew, done, trunc, info = env.step(np.hstack([action1, action2]))\n",
    "    obs2 = env.obs_agent_two()\n",
    "    l_obs.append(obs1)\n",
    "\n",
    "    if trunc:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f52381d0-ac2c-47e7-b65f-fa00c94befc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 5., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([-0.9810, -0.9747, -0.9858, -0.8817, -0.8749, -0.8916, -0.8944, -0.8231,\n",
      "        -0.9881, -0.9603, -0.9732, -0.8391, -0.8974, -0.8857, -0.7623, -0.0373,\n",
      "        -0.9550, -0.9709, -0.9668, -0.8289, -0.8865, -0.8856, -0.8970, -0.8203,\n",
      "        -0.9755], grad_fn=<AsStridedBackward0>)\n",
      "tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0373,\n",
      "        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tree_builder = TreeBuilder(0.99, 5)\n",
    "root_node = tree_builder.build_tree(l_obs[2], net, evaluation=True)\n",
    "\n",
    "print(root_node.N)\n",
    "print(root_node.Q)\n",
    "print((root_node.N!=0)*root_node.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f188d99-6398-4471-8af3-ff57c5f73861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])\n",
      "tensor([-0.9810, -0.9747, -0.9858, -0.8817, -0.8749, -0.8916, -0.8944, -0.8231,\n",
      "        -0.9881, -0.9603, -0.9732, -0.8391, -0.8974, -0.8857, -0.7623, -0.3115,\n",
      "        -0.9550, -0.9709, -0.9668, -0.8289, -0.8865, -0.8856, -0.8970, -0.8203,\n",
      "        -0.9755], grad_fn=<SelectBackward0>)\n",
      "tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "        -0.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tree_builder = TreeBuilder(0.99, 0)\n",
    "root_node = tree_builder.build_tree(l_obs[2], net, evaluation=True)\n",
    "\n",
    "print(root_node.N)\n",
    "print(root_node.Q)\n",
    "print((root_node.N!=0)*root_node.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1500c1f-31dc-44fa-89e4-eff4eb04959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
